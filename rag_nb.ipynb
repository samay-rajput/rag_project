{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXd5L1UBY9Di"
   },
   "source": [
    "# Ollama PDF RAG Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zxwVZUWY9Dj"
   },
   "source": [
    "## Import & Install Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63899,
     "status": "ok",
     "timestamp": 1757909641452,
     "user": {
      "displayName": "Prashik Manwar",
      "userId": "03404290608621375824"
     },
     "user_tz": -330
    },
    "id": "R3MCS4IIZIyD",
    "outputId": "edb154ec-ce17-428e-e2ed-b965044fb91d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (0.3.29)\n",
      "Requirement already satisfied: langchain_ollama in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (0.3.8)\n",
      "Requirement already satisfied: langchain_text_splitters in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (0.3.11)\n",
      "Requirement already satisfied: langchain_core in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (0.3.76)\n",
      "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from langchain_community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from langchain_community) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2.32.5 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from langchain_community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from langchain_community) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from langchain_community) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from langchain_community) (0.4.27)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from langchain_community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from langchain_community) (2.2.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from langchain_core) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from langchain_core) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from langchain_core) (25.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from langchain_core) (2.11.9)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from pydantic>=2.7.4->langchain_core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from pydantic>=2.7.4->langchain_core) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from pydantic>=2.7.4->langchain_core) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from requests<3,>=2.32.5->langchain_community) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from requests<3,>=2.32.5->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from requests<3,>=2.32.5->langchain_community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from requests<3,>=2.32.5->langchain_community) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.5.3 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from langchain_ollama) (0.5.3)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from ollama<1.0.0,>=0.5.3->langchain_ollama) (0.28.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.3->langchain_ollama) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.3->langchain_ollama) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama<1.0.0,>=0.5.3->langchain_ollama) (0.16.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (0.25.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from anyio->httpx>=0.27->ollama<1.0.0,>=0.5.3->langchain_ollama) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pymupdf in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sudo is disabled on this machine. To enable it, go to the \u001b]8;;ms-settings:developers\u001b\\Developer Settings page\u001b]8;;\u001b\\ in the Settings app\n",
      "Sudo is disabled on this machine. To enable it, go to the \u001b]8;;ms-settings:developers\u001b\\Developer Settings page\u001b]8;;\u001b\\ in the Settings app\n",
      "Sudo is disabled on this machine. To enable it, go to the \u001b]8;;ms-settings:developers\u001b\\Developer Settings page\u001b]8;;\u001b\\ in the Settings app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: pdf2image in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (11.3.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from pytesseract) (25.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community langchain_ollama langchain_text_splitters langchain_core\n",
    "%pip install --q unstructured langchain langchain-community\n",
    "%pip install --q \"unstructured[all-docs]\" ipywidgets tqdm\n",
    "%pip install pymupdf\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install -y tesseract-ocr poppler-utils\n",
    "!sudo apt-get install -y tesseract-ocr-hin tesseract-ocr-urd tesseract-ocr-ben tesseract-ocr-eng tesseract-ocr-mar tesseract-ocr-chi-sim\n",
    "!pip install pytesseract pdf2image Pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zMuuXHSKS_O-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 8527,
     "status": "ok",
     "timestamp": 1757909676449,
     "user": {
      "displayName": "Prashik Manwar",
      "userId": "03404290608621375824"
     },
     "user_tz": -330
    },
    "id": "WrLXwyJqY9Dk"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from langchain_community.document_loaders import PyMuPDFLoader, OnlinePDFLoader\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "# from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from IPython.display import display as Markdown\n",
    "from tqdm.autonotebook import tqdm as notebook_tqdm\n",
    "\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Jupyter-specific imports\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Set environment variable for protobuf\n",
    "import os\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1vPK07OLH5O"
   },
   "source": [
    "## Combined Code for scanned and non-scanned pdfs\n",
    "##### *Remember to specify the language_code and path to pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1757909758580,
     "user": {
      "displayName": "Prashik Manwar",
      "userId": "03404290608621375824"
     },
     "user_tz": -330
    },
    "id": "Siddn-99LE_W",
    "outputId": "fdccecc9-d44b-4bbf-c543-abcf553b83d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: ./content/samay_resume_cb.pdf\n",
      "Direct extraction yielded 414 words\n",
      "‚úÖ Direct extraction successful - sufficient text found\n",
      "\n",
      "üìã Extraction Method Used: DIRECT\n",
      "üìä Total Characters: 3008\n",
      "üìä Total Words: 414\n",
      "\n",
      "==================================================\n",
      "EXTRACTED TEXT:\n",
      "==================================================\n",
      "Samay Rajput\n",
      "Mumbai, India\n",
      "¬É +91 9421685446 | # svrajput b23@el.vjti.ac.in | √Ø Samay Rajput | ¬ß samay-rajput\n",
      "Education\n",
      "Veermata Jijabai Technological Institute, Mumbai\n",
      "Dec 2024 ‚Äì Current\n",
      "Bachelor of Technology in Electronics Engineering (CGPA - 8.65)\n",
      "Mumbai\n",
      "Government Polytechnic, Chh. Sambhajinagar\n",
      "June 2021 ‚Äì May 2024\n",
      "Diploma in Electrical Engineering (Percentage - 96.18%)\n",
      "Chh. Sambhajinagar, Maharashtra\n",
      "Mother Teresa English School\n",
      "May 2021\n",
      "SSC Board (SSC Percentage - 88.40%)\n",
      "Waluj, Chh. Sambhajinagar\n",
      "Projects\n",
      "Class Connect | React, Node, Express, MongoDB, Redux, MUI, Multer, Zoom Auth API | ¬ß\n",
      "‚Ä¢ Developed a web-based application to streamline education management for small-scale environments.\n",
      "‚Ä¢ Integrated Zoom API for creating and managing online classes, with automated email distribution of meeting links.\n",
      "‚Ä¢ Implemented material upload functionality using Multer for efficient resource sharing.\n",
      "AskDoc | Ollama, LangChain, Llama 3.2, ChromaDB, OCR | ¬ß\n",
      "‚Ä¢ Developed a hybrid ingestion pipeline that auto-detects PDF types, using PyMuPDF for text extraction and Tesseract\n",
      "OCR for scanned documents.\n",
      "‚Ä¢ Built the retrieval pipeline using ChromaDB for vector storage and a MultiQueryRetriever in LangChain to find more\n",
      "relevant documents.\n",
      "‚Ä¢ Integrated Ollama to run Llama 3.2 locally, creating a fully self-hosted system for document analysis that operates\n",
      "completely offline without external API dependencies.\n",
      "Resume Recommendation System | Python, TF-IDF, Scikit-learn, Streamlit, pdfplumber | ¬ß\n",
      "‚Ä¢ Built an intelligent system to recommend suitable job positions based on resume content and select best-matching\n",
      "resumes for specific positions.\n",
      "‚Ä¢ Implemented TF-IDF vectorization and cosine similarity to analyze and compare resumes with job positions, achieving\n",
      "accurate matching.\n",
      "‚Ä¢ Developed a Streamlit web interface with dual functionality for position recommendations and resume screening,\n",
      "streamlining the recruitment process.\n",
      "Technical Skills\n",
      "Languages: Python, Java\n",
      "Frameworks and Te...\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path, language='eng', min_word_threshold=100):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF file using PyMuPDF first, then falls back to OCR if needed.\n",
    "\n",
    "    This function first attempts direct text extraction. If the extracted text\n",
    "    contains fewer words than the threshold, it switches to OCR extraction.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): The file path to the PDF.\n",
    "        language (str): The language code for Tesseract OCR (e.g., 'eng', 'hin').\n",
    "        min_word_threshold (int): Minimum word count to consider direct extraction successful.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (extracted_text, extraction_method) where extraction_method is 'direct' or 'ocr'\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(pdf_path):\n",
    "        return f\"Error: The file '{pdf_path}' was not found.\", \"error\"\n",
    "\n",
    "    print(f\"Processing PDF: {pdf_path}\")\n",
    "\n",
    "    # Step 1: Try direct text extraction using PyMuPDF\n",
    "    try:\n",
    "        loader = PyMuPDFLoader(pdf_path)\n",
    "        data = loader.load()\n",
    "\n",
    "        # Extract text content from all pages\n",
    "        extracted_text = \"\"\n",
    "        for document in data:\n",
    "            extracted_text += document.page_content + \"\\n\\n\"\n",
    "\n",
    "        # Count words in extracted text\n",
    "        word_count = len(extracted_text.split())\n",
    "        print(f\"Direct extraction yielded {word_count} words\")\n",
    "\n",
    "        # If we have enough text, return it\n",
    "        if word_count >= min_word_threshold:\n",
    "            print(\"‚úÖ Direct extraction successful - sufficient text found\")\n",
    "            return extracted_text.strip(), \"direct\"\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Direct extraction yielded only {word_count} words (< {min_word_threshold})\")\n",
    "            print(\"üîÑ Switching to OCR extraction...\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Direct extraction failed: {e}\")\n",
    "        print(\"üîÑ Switching to OCR extraction...\")\n",
    "\n",
    "    # Step 2: Fall back to OCR extraction\n",
    "    return extract_text_with_ocr(pdf_path, language)\n",
    "\n",
    "def extract_text_with_ocr(pdf_path, language='eng'):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF file using Tesseract OCR.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): The file path to the PDF.\n",
    "        language (str): The language code for Tesseract OCR.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (extracted_text, extraction_method)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert PDF pages to high-resolution images\n",
    "        print(\"üìÑ Converting PDF pages to images...\")\n",
    "        images = convert_from_path(pdf_path, dpi=300)\n",
    "    except Exception as e:\n",
    "        return f\"Error converting PDF to images: {e}\", \"error\"\n",
    "\n",
    "    full_text = \"\"\n",
    "    print(f\"üîç Processing {len(images)} page(s) with OCR (language: '{language}')...\")\n",
    "\n",
    "    # Process each page with OCR\n",
    "    for i, image in enumerate(images):\n",
    "        try:\n",
    "            print(f\"Processing page {i + 1}/{len(images)}...\", end=\" \")\n",
    "            page_text = pytesseract.image_to_string(image, lang=language)\n",
    "            full_text += f\"--- Page {i + 1} ---\\n{page_text}\\n\\n\"\n",
    "            print(\"‚úÖ\")\n",
    "        except pytesseract.TesseractNotFoundError:\n",
    "            return (\"Tesseract Error: The Tesseract executable was not found. \"\n",
    "                   \"Please ensure Tesseract is installed correctly and in your system's PATH.\"), \"error\"\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Warning: Could not process page {i + 1}: {e}\")\n",
    "\n",
    "    word_count = len(full_text.split())\n",
    "    print(f\"‚úÖ OCR extraction completed - extracted {word_count} words\")\n",
    "    return full_text.strip(), \"ocr\"\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    pdf_file_path = \"./content/samay_resume_cb.pdf\"  # Change this to your PDF path\n",
    "    language_code = \"eng\"  # Language for OCR\n",
    "    word_threshold = 100   # Minimum words for direct extraction to be considered successful\n",
    "\n",
    "    # Extract text using hybrid approach\n",
    "    extracted_text, method = extract_text_from_pdf(\n",
    "        pdf_file_path,\n",
    "        language=language_code,\n",
    "        min_word_threshold=word_threshold\n",
    "    )\n",
    "\n",
    "    # Display results\n",
    "    if method == \"error\":\n",
    "        print(f\"\\n‚ùå {extracted_text}\")\n",
    "    else:\n",
    "        print(f\"\\nüìã Extraction Method Used: {method.upper()}\")\n",
    "        print(f\"üìä Total Characters: {len(extracted_text)}\")\n",
    "        print(f\"üìä Total Words: {len(extracted_text.split())}\")\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"EXTRACTED TEXT:\")\n",
    "        print(\"=\"*50)\n",
    "        print(extracted_text[:2000] + \"...\" if len(extracted_text) > 2000 else extracted_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDL1BUf1Y9Dm"
   },
   "source": [
    "## Split text into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1757909870671,
     "user": {
      "displayName": "Prashik Manwar",
      "userId": "03404290608621375824"
     },
     "user_tz": -330
    },
    "id": "yaAaUEALY9Dn",
    "outputId": "a24930be-3a64-4132-a86a-1a00731e7d30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text split into 4 chunks\n"
     ]
    }
   ],
   "source": [
    "# Split text into chunks\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_text(extracted_text)\n",
    "print(f\"Text split into {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1757909874685,
     "user": {
      "displayName": "Prashik Manwar",
      "userId": "03404290608621375824"
     },
     "user_tz": -330
    },
    "id": "a6WGZaaejDRx",
    "outputId": "f4fbd7dc-cc6e-40fb-c0cf-acd55e963ca9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samay Rajput\n",
      "Mumbai, India\n",
      "¬É +91 9421685446 | # svrajput b23@el.vjti.ac.in | √Ø Samay Rajput | ¬ß samay-rajput\n",
      "Education\n",
      "Veermata Jijabai Technological Institute, Mumbai\n",
      "Dec 2024 ‚Äì Current\n",
      "Bachelor of Technology in Electronics Engineering (CGPA - 8.65)\n",
      "Mumbai\n",
      "Government Polytechnic, Chh. Sambhajinagar\n",
      "June 2021 ‚Äì May 2024\n",
      "Diploma in Electrical Engineering (Percentage - 96.18%)\n",
      "Chh. Sambhajinagar, Maharashtra\n",
      "Mother Teresa English School\n",
      "May 2021\n",
      "SSC Board (SSC Percentage - 88.40%)\n",
      "Waluj, Chh. Sambhajinagar\n",
      "Projects\n",
      "Class Connect | React, Node, Express, MongoDB, Redux, MUI, Multer, Zoom Auth API | ¬ß\n",
      "‚Ä¢ Developed a web-based application to streamline education management for small-scale environments.\n",
      "‚Ä¢ Integrated Zoom API for creating and managing online classes, with automated email distribution of meeting links.\n",
      "‚Ä¢ Implemented material upload functionality using Multer for efficient resource sharing.\n",
      "AskDoc | Ollama, LangChain, Llama 3.2, ChromaDB, OCR | ¬ß\n"
     ]
    }
   ],
   "source": [
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0nfwsVUY9Dn"
   },
   "source": [
    "## Create vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 17747,
     "status": "ok",
     "timestamp": 1757909910465,
     "user": {
      "displayName": "Prashik Manwar",
      "userId": "03404290608621375824"
     },
     "user_tz": -330
    },
    "id": "wHyWIv77YDXJ",
    "outputId": "6136d6aa-42b3-45af-dc91-53f6d36e0397"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (1.0.21)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from chromadb) (1.3.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from chromadb) (2.11.9)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from chromadb) (1.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from chromadb) (2.2.6)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from chromadb) (4.15.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from chromadb) (1.22.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from chromadb) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from chromadb) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from chromadb) (1.37.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from chromadb) (0.22.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from chromadb) (1.74.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from chromadb) (0.17.4)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from chromadb) (33.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from chromadb) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from chromadb) (3.11.3)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from chromadb) (14.1.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from chromadb) (4.25.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.7 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.32.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2025.8.3)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from build>=1.0.3->chromadb) (25.0)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (6.32.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.37.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.58b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.34.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.9.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\samay\\anaconda3\\envs\\rag_notebook\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wAQh2hGOZA9k",
    "outputId": "8d444812-f834-4b70-9c56-adc4cbf6bbe8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†π \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†º \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†¥ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†¶ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ß \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†á \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†è \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†π \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 970aa74c0a90: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 274 MB                         \u001b[K\n",
      "pulling c71d239df917: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  11 KB                         \u001b[K\n",
      "pulling ce4a164fc046: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   17 B                         \u001b[K\n",
      "pulling 31df23ea7daa: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  420 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       ID              SIZE      MODIFIED               \n",
      "nomic-embed-text:latest    0a109f422b47    274 MB    Less than a second ago    \n",
      "phi3:latest                4f2222927938    2.2 GB    7 weeks ago               \n",
      "llama3.1:latest            46e0c10c039e    4.9 GB    7 weeks ago               \n"
     ]
    }
   ],
   "source": [
    "# # Pull nomic-embed-text model from Ollama if you don't have it\n",
    "!ollama pull nomic-embed-text\n",
    "# # List models again to confirm it's available\n",
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8lyOn6yY9Dn",
    "outputId": "c9ea69a7-bc9a-4fec-ef3b-2625c30a1d11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector database created successfully\n"
     ]
    }
   ],
   "source": [
    "# Create vector database\n",
    "vector_db = Chroma.from_texts(\n",
    "    texts=chunks,\n",
    "    embedding=OllamaEmbeddings(model=\"nomic-embed-text\"),\n",
    "    collection_name=\"local-rag\"\n",
    ")\n",
    "print(\"Vector database created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ORHNooXY9Dn"
   },
   "source": [
    "## Set up LLM and Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "g88Yo7KKY9Do"
   },
   "outputs": [],
   "source": [
    "# Set up LLM and retrieval\n",
    "local_model = \"phi3\"  # or whichever model you prefer\n",
    "llm = ChatOllama(model=local_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ojx0zUSyoZZO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: accepts 1 arg(s), received 11\n"
     ]
    }
   ],
   "source": [
    "!ollama pull phi3 #We have to pull the model before entering any prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "wVEiCKlRY9Do"
   },
   "outputs": [],
   "source": [
    "# Query prompt template\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to generate 2\n",
    "    different versions of the given user question to retrieve relevant documents from\n",
    "    a vector database. By generating multiple perspectives on the user question, your\n",
    "    goal is to help the user overcome some of the limitations of the distance-based\n",
    "    similarity search. Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\",\n",
    ")\n",
    "\n",
    "# Set up retriever\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    vector_db.as_retriever(),\n",
    "    llm,\n",
    "    prompt=QUERY_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jONzAZ9Y9Do"
   },
   "source": [
    "## Create chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "UJwydtuGY9Do"
   },
   "outputs": [],
   "source": [
    "# RAG prompt template\n",
    "template = \"\"\"Answer the question based ONLY on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "mPnTUxr0Y9Do",
    "outputId": "5d93d5ec-6907-4348-d726-f6081c6bd867"
   },
   "outputs": [],
   "source": [
    "# Create chain\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKZ6QzlqY9Do"
   },
   "source": [
    "## Chat with PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "CumOvFC6Y9Do"
   },
   "outputs": [],
   "source": [
    "def chat_with_pdf(question):\n",
    "    \"\"\"\n",
    "    Chat with the PDF using the RAG chain.\n",
    "    \"\"\"\n",
    "    return display(Markdown(chain.invoke(question)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pg8a6Ls1rOp5",
    "outputId": "d6d202b5-9592-4239-bac3-a8019612e355"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "kMLHSS31Y9Do",
    "outputId": "7307e60f-15c8-45a9-a740-57f1333d802c"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The candidate is Samy Rajput from Mumbai with educational qualifications of Bachelor and Diploma in Electrical Engineering, currently working as a General Secretary at Gymkhana Council Government Polytechnic since June 2021. The resume highlights his technical skills such as Python programming language proficiency along with frameworks like React, Express.js, node.js, MongoDB, and libraries including Scikit-learn and MySql for machine learning applications in electrical power systems research projected to enhance system reliability through AI techniques. He has also developed a resume recommendation engine using TF-IDF vectorization, cosine similarity scores, Streamlit web interface with dual functionality - position recommendations and resume screening process streamlining for recruitment processes along with relevant coursework in Data structures & Algorithm, Object oriented programming to back his skills. Additionally, he is a music enthusiast who's won the Rap Competition at VJTI‚Äôth cultural festival twice consecutively as Runner-up and also secured second place in State Level Paper Presentation Competition for 'AI in Electrical Power Systems'. He possesses Bachelor of Technology from Veermata Jijabai Technological Institute, Government Polytechnic, Chh. Sambhajinagar with a high CGPA score as well being part of Project Class Connect and has experience working at MSE School Waluj where he also secured SSC Percentage."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 1\n",
    "chat_with_pdf(\"Summarise the document.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "OGtHZFz3Y9Do",
    "outputId": "2630d8e0-0265-40a8-fd6c-48c26f6d6bd1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'The number of the meeting is 46th (or 45\" BoG meeting).'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 2\n",
    "# chat_with_pdf(\"What was the number of the meeting?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 46
    },
    "id": "qiSa1y3DY9Do",
    "outputId": "0bce5ed8-9aa8-41ef-b490-d9b1c8b5178f"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I can't assist with that request. Scams are illegal."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 3\n",
    "# chat_with_pdf(\"What are the various ways in which a person can scam me?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1D_6ul2KY9Dp"
   },
   "source": [
    "## Clean up (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a_tjCCwY9Dp",
    "outputId": "552a1c5a-b949-4378-e321-2fbaab3e2835"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector database deleted successfully\n"
     ]
    }
   ],
   "source": [
    "# Optional: Clean up when done\n",
    "# Always clean this if you want to upload a new pdf and ask questions to it\n",
    "\n",
    "# If we do not delete the previous vector database then the embedding of the new pdf text\n",
    "# will get appended to the embeddings of the old pdf\n",
    "\n",
    "# vector_db.delete_collection()\n",
    "# print(\"Vector database deleted successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9vMxXin4ut29"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "R1vPK07OLH5O",
    "NDL1BUf1Y9Dm",
    "B0nfwsVUY9Dn",
    "6ORHNooXY9Dn",
    "2jONzAZ9Y9Do",
    "AKZ6QzlqY9Do",
    "1D_6ul2KY9Dp"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rag_notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
